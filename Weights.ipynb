{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 07:40:35.504545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "DATA_DIR = tf.keras.utils.get_file(\n",
    "    \"modelnet.zip\",\n",
    "    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "DATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHOOSE THE CLASSES\n",
    "2 classes that we use to train PointNet model, there is no much difference in which two classes do you choose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chair_t = 'chair_bathtub'\n",
    "chair_t = 'dresser_chair' \n",
    "# chair_t = 'sofa_table'\n",
    "#chair_t = 'chair_6'\n",
    "d_max = 1024 #  size of latent space \n",
    "batch = 1\n",
    "BATCH_SIZE  = batch # batch size, the best results for batch = 1\n",
    "num_points = 512  # num_points = sample_size \n",
    "NUM_CLASSES = 2\n",
    "NUM_POINTS = num_points\n",
    "epochs = 20 # number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "weights_path = os.path.join(current_directory, 'new_weights/') # where to save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(num_points=num_points):\n",
    "\n",
    "    train_points = []\n",
    "    train_labels = []\n",
    "    test_points = []\n",
    "    test_labels = []\n",
    "    \n",
    "    \n",
    "    class_map = {}\n",
    "    folders_1 = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n",
    "    folders = [None]*2\n",
    "    if chair_t == 'chair_bathtub':\n",
    "        folders[0] = folders_1[2] #chair\n",
    "        folders[1] = folders_1[4] #bathtub\n",
    "    elif chair_t == 'dresser_chair':\n",
    "        folders[0] = folders_1[0] #dresser\n",
    "        folders[1] = folders_1[2] #chair\n",
    "    elif chair_t == 'sofa_table':\n",
    "        folders[0] = folders_1[3] #sofa\n",
    "        folders[1] = folders_1[6] #table\n",
    "    elif chair_t == 'chair_6':\n",
    "        folders[0] = folders_1[0] \n",
    "        folders[1] = folders_1[1] \n",
    "        folders[2] = folders_1[2] \n",
    "        folders[3] = folders_1[3] \n",
    "        folders[4] = folders_1[4] \n",
    "        folders[5] = folders_1[5] \n",
    "\n",
    "\n",
    "    for i, folder in enumerate(folders):\n",
    "        print(\"processing class: {}\".format(os.path.basename(folder)))\n",
    "        # store folder name with ID so we can retrieve later\n",
    "        class_map[i] = folder.split(\"/\")[-1]\n",
    "        # gather all files\n",
    "        train_files = glob.glob(os.path.join(folder, \"train/*\"))\n",
    "        test_files = glob.glob(os.path.join(folder, \"test/*\"))\n",
    "\n",
    "        for f in train_files:\n",
    "            train_points.append(trimesh.load(f).sample(num_points)) #Breaking the image into points \n",
    "            train_labels.append(i)                                  # and add it to array\n",
    "\n",
    "        for f in test_files:\n",
    "            test_points.append(trimesh.load(f).sample(num_points))\n",
    "            test_labels.append(i)\n",
    "\n",
    "    return (\n",
    "        np.array(train_points),\n",
    "        np.array(test_points),\n",
    "        np.array(train_labels),\n",
    "        np.array(test_labels),\n",
    "        class_map,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing class: bathtub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing class: monitor\n"
     ]
    }
   ],
   "source": [
    "NUM_POINTS = num_points\n",
    "\n",
    "train_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(\n",
    "    NUM_POINTS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 07:41:50.880710: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-09 07:41:50.882267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-12-09 07:41:50.898342: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-12-09 07:41:50.898359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2023-12-09 07:41:50.898974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-09 07:41:50.902893: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "def augment(points, label):                                                   \n",
    "    # jitter points                                                           \n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    # shuffle points\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points, label\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)\n",
    "\n",
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "    \n",
    "def tnet(inputs, num_features):\n",
    "\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "    \n",
    "    x = conv_bn(inputs, 64)\n",
    "    x = conv_bn(x, 128)\n",
    "    x = conv_bn(x, 1024)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 512)\n",
    "    x = dense_bn(x, 256)\n",
    "    \n",
    "        \n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
    "\n",
    "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
    "\n",
    "x = tnet(inputs, 3)\n",
    "\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 64)\n",
    "x = tnet(x, 64)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 128)\n",
    "if d_max == 1024:\n",
    "    x = conv_bn(x, 1024)\n",
    "elif d_max == 512:\n",
    "    x = conv_bn(x, 512)\n",
    "elif d_max == 2048:\n",
    "    x = conv_bn(x, 2048)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 512)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pointnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 512, 64)      256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 64)      256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 512, 128)     8320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 128)     512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 512, 1024)    132096      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 1024)    4096        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512, 1024)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 1024)         0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          524800      global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 512)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 9)            2313        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 3, 3)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 512, 3)       0           input_1[0][0]                    \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 512, 64)      256         dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512, 64)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 512, 64)      4160        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 512, 64)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 512, 64)      4160        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 512, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 512, 128)     8320        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 512, 128)     512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 512, 128)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 512, 1024)    132096      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 512, 1024)    4096        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 512, 1024)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 1024)         0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          524800      global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 512)          2048        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 512)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 256)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4096)         1052672     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64, 64)       0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 512, 64)      0           activation_6[0][0]               \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 512, 64)      4160        dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 512, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 512, 128)     8320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 512, 128)     512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 512, 128)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 512, 1024)    132096      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 512, 1024)    4096        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 512, 1024)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 1024)         0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          524800      global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 512)          2048        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 512)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256)          1024        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            257         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,482,186\n",
      "Trainable params: 3,470,026\n",
      "Non-trainable params: 12,160\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 07:41:51.338558: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-12-09 07:41:51.350814: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 38s 60ms/step - loss: 0.6649 - accuracy: 0.8296 - val_loss: 302053.1875 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "571/571 [==============================] - 32s 56ms/step - loss: 0.5910 - accuracy: 0.8142 - val_loss: 34812.5781 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.5471 - accuracy: 0.8122 - val_loss: 84389.0234 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "571/571 [==============================] - 32s 56ms/step - loss: 0.5345 - accuracy: 0.7952 - val_loss: 228534.2344 - val_accuracy: 0.6333\n",
      "Epoch 5/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.5046 - accuracy: 0.8123 - val_loss: 223489.2500 - val_accuracy: 0.6533\n",
      "Epoch 6/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.4996 - accuracy: 0.8090 - val_loss: 212536.5781 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "571/571 [==============================] - 32s 55ms/step - loss: 0.4735 - accuracy: 0.8273 - val_loss: 99515.3438 - val_accuracy: 0.6400\n",
      "Epoch 8/20\n",
      "571/571 [==============================] - 32s 55ms/step - loss: 0.5114 - accuracy: 0.7928 - val_loss: 287187.0312 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "571/571 [==============================] - 32s 55ms/step - loss: 0.4456 - accuracy: 0.8437 - val_loss: 185747.0156 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.5066 - accuracy: 0.7957 - val_loss: 350194.4375 - val_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 31s 54ms/step - loss: 0.4994 - accuracy: 0.8008 - val_loss: 58049.3398 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.4871 - accuracy: 0.8097 - val_loss: 34886.0820 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.5077 - accuracy: 0.7949 - val_loss: 210999.9531 - val_accuracy: 0.6333\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.4411 - accuracy: 0.8417 - val_loss: 323411.5938 - val_accuracy: 0.6600\n",
      "Epoch 15/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.4684 - accuracy: 0.8225 - val_loss: 228716.0469 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.4834 - accuracy: 0.8120 - val_loss: 676029.3750 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.4958 - accuracy: 0.8034 - val_loss: 356447.4688 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 31s 54ms/step - loss: 0.4573 - accuracy: 0.8300 - val_loss: 138806.2188 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 31s 55ms/step - loss: 0.4547 - accuracy: 0.8317 - val_loss: 350793.7500 - val_accuracy: 0.6667\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 32s 55ms/step - loss: 0.4641 - accuracy: 0.8252 - val_loss: 293348.1562 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DAVIDSON/dmkurdydyk/.conda/envs/aot/lib/python3.8/site-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "if NUM_CLASSES == 2:\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # Single output neuron for binary classification\n",
    "    loss_function = \"binary_crossentropy\"\n",
    "    metrics = [\"accuracy\"]\n",
    "else:\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)  # Multiple output neurons for multi-class\n",
    "    loss_function = \"sparse_categorical_crossentropy\"\n",
    "    metrics = [\"sparse_categorical_accuracy\"]\n",
    "\n",
    "# Define the model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=loss_function,\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=20, validation_data=test_dataset)\n",
    "\n",
    "weights_chair = model.get_weights()\n",
    "\n",
    "# Construct the file name using all parameters\n",
    "weights_filename = f\"weights_{chair_t}_{NUM_CLASSES}_{num_points}_{batch}_{epochs}_{d_max}.npy\"\n",
    "\n",
    "# Save the model weights\n",
    "np.save(weights_path + weights_filename, weights_chair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
