{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 17:43:51.053194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "DATA_DIR = tf.keras.utils.get_file(\n",
    "    \"modelnet.zip\",\n",
    "    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "DATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHOOSE THE CLASSES\n",
    "2 classes that we use to train PointNet model, there is no much difference in which two classes do you choose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chair_t = 'chair_bathtub'\n",
    "# chair_t = 'dresser_chair' \n",
    "chair_t = 'sofa_table'\n",
    "#chair_t = 'chair_6'\n",
    "d_max = 1024 #  size of latent space \n",
    "batch = 1\n",
    "BATCH_SIZE  = batch # batch size, the best results for batch = 1\n",
    "num_points = 512  # num_points = sample_size \n",
    "NUM_CLASSES = 2\n",
    "NUM_POINTS = num_points\n",
    "epochs = 20 # number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "weights_path = os.path.join(current_directory, 'new_weights/') # where to save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(num_points=num_points):\n",
    "\n",
    "    train_points = []\n",
    "    train_labels = []\n",
    "    test_points = []\n",
    "    test_labels = []\n",
    "    \n",
    "    \n",
    "    class_map = {}\n",
    "    folders_1 = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n",
    "    folders = [None]*2\n",
    "    if chair_t == 'chair_bathtub':\n",
    "        folders[0] = folders_1[2] #chair\n",
    "        folders[1] = folders_1[4] #bathtub\n",
    "    elif chair_t == 'dresser_chair':\n",
    "        folders[0] = folders_1[0] #dresser\n",
    "        folders[1] = folders_1[2] #chair\n",
    "    elif chair_t == 'sofa_table':\n",
    "        folders[0] = folders_1[3] #sofa\n",
    "        folders[1] = folders_1[6] #table\n",
    "    elif chair_t == 'chair_6':\n",
    "        folders[0] = folders_1[0] \n",
    "        folders[1] = folders_1[1] \n",
    "        folders[2] = folders_1[2] \n",
    "        folders[3] = folders_1[3] \n",
    "        folders[4] = folders_1[4] \n",
    "        folders[5] = folders_1[5] \n",
    "\n",
    "\n",
    "    for i, folder in enumerate(folders):\n",
    "        print(\"processing class: {}\".format(os.path.basename(folder)))\n",
    "        # store folder name with ID so we can retrieve later\n",
    "        class_map[i] = folder.split(\"/\")[-1]\n",
    "        # gather all files\n",
    "        train_files = glob.glob(os.path.join(folder, \"train/*\"))\n",
    "        test_files = glob.glob(os.path.join(folder, \"test/*\"))\n",
    "\n",
    "        for f in train_files:\n",
    "            train_points.append(trimesh.load(f).sample(num_points)) #Breaking the image into points \n",
    "            train_labels.append(i)                                  # and add it to array\n",
    "\n",
    "        for f in test_files:\n",
    "            test_points.append(trimesh.load(f).sample(num_points))\n",
    "            test_labels.append(i)\n",
    "\n",
    "    return (\n",
    "        np.array(train_points),\n",
    "        np.array(test_points),\n",
    "        np.array(train_labels),\n",
    "        np.array(test_labels),\n",
    "        class_map,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing class: desk\n",
      "processing class: dresser\n"
     ]
    }
   ],
   "source": [
    "NUM_POINTS = num_points\n",
    "\n",
    "train_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(\n",
    "    NUM_POINTS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pointnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 512, 64)      256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 512, 128)     8320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512, 128)     512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 512, 128)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 512, 1024)    132096      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512, 1024)    4096        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 512, 1024)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 1024)         0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          524800      global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 512)          2048        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 512)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          131328      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256)          1024        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 9)            2313        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 3, 3)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 512, 3)       0           input_2[0][0]                    \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 512, 64)      256         dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 512, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 512, 64)      4160        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 512, 64)      4160        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 512, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 512, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 512, 128)     8320        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 512, 128)     512         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512, 128)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 512, 1024)    132096      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 512, 1024)    4096        conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 512, 1024)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 1024)         0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          524800      global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 512)          2048        dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 512)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          131328      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4096)         1052672     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64, 64)       0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 512, 64)      0           activation_23[0][0]              \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 512, 64)      4160        dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 512, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 512, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 512, 128)     8320        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 512, 128)     512         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 512, 128)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 512, 1024)    132096      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 512, 1024)    4096        conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 512, 1024)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 1024)         0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          524800      global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 512)          2048        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 512)          0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          131328      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 256)          1024        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256)          0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            514         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,482,443\n",
      "Trainable params: 3,470,283\n",
      "Non-trainable params: 12,160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def augment(points, label):                                                   # Перетасовываем наши данные \n",
    "    # jitter points                                                           \n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    # shuffle points\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points, label\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)\n",
    "\n",
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "    \n",
    "def tnet(inputs, num_features):\n",
    "\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "    \n",
    "    x = conv_bn(inputs, 64)\n",
    "    x = conv_bn(x, 128)\n",
    "    x = conv_bn(x, 1024)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 512)\n",
    "    x = dense_bn(x, 256)\n",
    "    \n",
    "        \n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
    "\n",
    "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
    "\n",
    "x = tnet(inputs, 3)\n",
    "\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 64)\n",
    "x = tnet(x, 64)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 128)\n",
    "if d_max == 1024:\n",
    "    x = conv_bn(x, 1024)\n",
    "elif d_max == 512:\n",
    "    x = conv_bn(x, 512)\n",
    "elif d_max == 2048:\n",
    "    x = conv_bn(x, 2048)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 512)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pointnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 512, 64)      256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 64)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 512, 128)     8320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512, 128)     512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 512, 128)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 512, 1024)    132096      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512, 1024)    4096        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 512, 1024)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 1024)         0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          524800      global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 512)          2048        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 512)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          131328      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256)          1024        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 9)            2313        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 3, 3)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 512, 3)       0           input_2[0][0]                    \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 512, 64)      256         dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 512, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 64)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 512, 64)      4160        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512, 64)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 512, 64)      4160        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 512, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 512, 64)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 512, 128)     8320        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 512, 128)     512         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512, 128)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 512, 1024)    132096      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 512, 1024)    4096        conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 512, 1024)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 1024)         0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          524800      global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 512)          2048        dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 512)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          131328      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4096)         1052672     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64, 64)       0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 512, 64)      0           activation_23[0][0]              \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 512, 64)      4160        dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 512, 64)      256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 512, 64)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 512, 128)     8320        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 512, 128)     512         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 512, 128)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 512, 1024)    132096      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 512, 1024)    4096        conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 512, 1024)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 1024)         0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          524800      global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 512)          2048        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 512)          0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          131328      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 256)          1024        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256)          0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            257         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,482,186\n",
      "Trainable params: 3,470,026\n",
      "Non-trainable params: 12,160\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "400/400 [==============================] - 25s 54ms/step - loss: 0.6933 - accuracy: 0.4805 - val_loss: 2183.5320 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6934 - accuracy: 0.4476 - val_loss: 963.8888 - val_accuracy: 0.4651\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6934 - accuracy: 0.4483 - val_loss: 2094.0708 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6932 - accuracy: 0.5073 - val_loss: 2711.6069 - val_accuracy: 0.2791\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6934 - accuracy: 0.4636 - val_loss: 1684.4032 - val_accuracy: 0.3198\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6933 - accuracy: 0.4754 - val_loss: 2221.0413 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6933 - accuracy: 0.4851 - val_loss: 740.8107 - val_accuracy: 0.3837\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6932 - accuracy: 0.4809 - val_loss: 1539.2731 - val_accuracy: 0.4128\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6933 - accuracy: 0.4840 - val_loss: 3051.4524 - val_accuracy: 0.4884\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6934 - accuracy: 0.4280 - val_loss: 2956.3362 - val_accuracy: 0.4942\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6933 - accuracy: 0.4670 - val_loss: 1612.9333 - val_accuracy: 0.4942\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6934 - accuracy: 0.4753 - val_loss: 1845.0201 - val_accuracy: 0.5116\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6933 - accuracy: 0.5164 - val_loss: 1938.8500 - val_accuracy: 0.4709\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 21s 54ms/step - loss: 0.6933 - accuracy: 0.5032 - val_loss: 1858.9331 - val_accuracy: 0.4244\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6931 - accuracy: 0.5397 - val_loss: 1252.5510 - val_accuracy: 0.5058\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 23s 57ms/step - loss: 0.6933 - accuracy: 0.4573 - val_loss: 765.7018 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.6933 - accuracy: 0.5314 - val_loss: 1475.9153 - val_accuracy: 0.5174\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6933 - accuracy: 0.4422 - val_loss: 1688.6718 - val_accuracy: 0.5116\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6934 - accuracy: 0.4642 - val_loss: 3345.3840 - val_accuracy: 0.4884\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6933 - accuracy: 0.4915 - val_loss: 3547.0588 - val_accuracy: 0.4535\n"
     ]
    }
   ],
   "source": [
    "if NUM_CLASSES == 2:\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # Single output neuron for binary classification\n",
    "    loss_function = \"binary_crossentropy\"\n",
    "    metrics = [\"accuracy\"]\n",
    "else:\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)  # Multiple output neurons for multi-class\n",
    "    loss_function = \"sparse_categorical_crossentropy\"\n",
    "    metrics = [\"sparse_categorical_accuracy\"]\n",
    "\n",
    "# Define the model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=loss_function,\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=20, validation_data=test_dataset)\n",
    "\n",
    "weights_chair = model.get_weights()\n",
    "\n",
    "# Construct the file name using all parameters\n",
    "weights_filename = f\"weights_{chair_t}_{NUM_CLASSES}_{num_points}_{batch}_{epochs}_{d_max}.npy\"\n",
    "\n",
    "# Save the model weights\n",
    "np.save(weights_path + weights_filename, weights_chair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
