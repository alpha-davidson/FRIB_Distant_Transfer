{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:57:37.814552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/DAVIDSON/dmkurdydyk/.conda/envs/aot/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import click \n",
    "import umap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Paths\n",
    "data_raw_where = base_dir + '/data/' # where the raw data(before sampling) were stored\n",
    "data_sampled_where = base_dir + '/data/data_sampled' # where the sampled data were stored\n",
    "weights_path = base_dir + '/new_weights/' # where the weights were stored\n",
    "predict_where = base_dir + '/new_one_class_SVM_predict/' # Where to save predictions\n",
    "umap_where = base_dir + '/umap_plots/' # where to save umap plots\n",
    "\n",
    "# Constants\n",
    "ISOTOPE = 'O16'\n",
    "folder = base_dir + '/datalessthan5/'\n",
    "sample_size = 512 # sample size = num_points \n",
    "d_max = 1024 # Size of latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (1, 64, 128) not compatible with provided weight shape (1, 64, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(layer, keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv1D):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m         \u001b[39m# Conv1D layers expect two sets of weights: kernel and bias\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m         layer\u001b[39m.\u001b[39;49mset_weights([npy_weights[weight_counter], npy_weights[weight_counter \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m]])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m         weight_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(layer, keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m         \u001b[39m# BatchNormalization layers expect four sets of weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/aot/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1871\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1869\u001b[0m ref_shape \u001b[39m=\u001b[39m param\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1870\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ref_shape\u001b[39m.\u001b[39mis_compatible_with(weight\u001b[39m.\u001b[39mshape):\n\u001b[0;32m-> 1871\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1872\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mLayer weight shape \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m not compatible with provided weight \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1873\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (ref_shape, weight\u001b[39m.\u001b[39mshape))\n\u001b[1;32m   1874\u001b[0m weight_value_tuples\u001b[39m.\u001b[39mappend((param, weight))\n\u001b[1;32m   1875\u001b[0m weight_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer weight shape (1, 64, 128) not compatible with provided weight shape (1, 64, 64)"
     ]
    }
   ],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'l2reg': self.l2reg,\n",
    "               'num_features': self.num_features,\n",
    "               'eye': self.eye.numpy().tolist()}\n",
    "    \n",
    "def tnet(inputs, num_features):\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "    \n",
    "    x = conv_bn(inputs, 64) #64->32\n",
    "    x = conv_bn(x, 128) #128 -> 64\n",
    "    x = conv_bn(x, 1024) #1024 -> 512\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 512) # 512 -> 256\n",
    "    x = dense_bn(x, 256) #256 -> 128\n",
    "        \n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
    "\n",
    "# PointNet for multi-class classification\n",
    "def create_pointnet(num_points, num_classes, input_dimension=3):\n",
    "    inputs = keras.Input(shape=(num_points, input_dimension))\n",
    "\n",
    "    # T-Net layers\n",
    "    x = tnet(inputs, input_dimension)\n",
    "\n",
    "    # PointNet layers\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 128)\n",
    "    x = conv_bn(x, 1024)  # Adjust the size according to your d_max\n",
    "    global_features = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Fully connected layers for classification\n",
    "    x = dense_bn(global_features, 512)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Adjust the output layer according to the number of classes\n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # Use sigmoid for binary classification\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation=\"softmax\")(x)  # Use softmax for multi-class\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"PointNet\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Set your parameters\n",
    "num_points = 512  # Example: number of points in each sample\n",
    "num_classes = 3  # Set the number of classes for your task\n",
    "input_dimension = 3  # Assuming 3D input data (X, Y, Z)\n",
    "\n",
    "# Create the model\n",
    "model = create_pointnet(num_points, num_classes, input_dimension)\n",
    "\n",
    "path = weights_path + 'weights_dresser_chair_2_512_1_20_1024.npy'\n",
    "\n",
    "npy_weights = np.load(path, allow_pickle=True)\n",
    "\n",
    "# Initialize a counter to keep track of the weight set\n",
    "weight_counter = 0\n",
    "\n",
    "# Manually assign weights to each layer\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, keras.layers.Conv1D):\n",
    "        # Conv1D layers expect two sets of weights: kernel and bias\n",
    "        layer.set_weights([npy_weights[weight_counter], npy_weights[weight_counter + 1]])\n",
    "        weight_counter += 2\n",
    "    elif isinstance(layer, keras.layers.BatchNormalization):\n",
    "        # BatchNormalization layers expect four sets of weights\n",
    "        layer.set_weights(npy_weights[weight_counter:weight_counter + 4])\n",
    "        weight_counter += 4\n",
    "    elif isinstance(layer, keras.layers.Dense):\n",
    "        # Dense layers expect two sets of weights: kernel and bias\n",
    "        layer.set_weights([npy_weights[weight_counter], npy_weights[weight_counter + 1]])\n",
    "        weight_counter += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weight sets in npy file: 108\n",
      "Number of trainable weights in the model: 44\n",
      "Layer conv1d_12: Expected 2, Found 64\n",
      "  - Weight shape: expected (1, 3, 64), found ()\n",
      "  - Weight shape: expected (64,), found ()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"conv1d_12\" with a weight list of length 64, but the layer was expecting 2 weights. Provided weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  - Weight shape: expected \u001b[39m\u001b[39m{\u001b[39;00mtw\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, found \u001b[39m\u001b[39m{\u001b[39;00mlw\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Set the weights\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bphy3kuchera.davidson.edu/home/DAVIDSON/dmkurdydyk/FRIB_Distant_Transfer/O16_multi_class_dw.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m layer\u001b[39m.\u001b[39;49mset_weights(layer_weights)\n",
      "File \u001b[0;32m~/.conda/envs/aot/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1853\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1850\u001b[0m     expected_num_weights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1852\u001b[0m \u001b[39mif\u001b[39;00m expected_num_weights \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(weights):\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1854\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mYou called `set_weights(weights)` on layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1855\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mwith a weight list of length \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, but the layer was \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1856\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mexpecting \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m weights. Provided weights: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1857\u001b[0m       (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mlen\u001b[39m(weights), expected_num_weights, \u001b[39mstr\u001b[39m(weights)[:\u001b[39m50\u001b[39m]))\n\u001b[1;32m   1859\u001b[0m weight_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1860\u001b[0m weight_value_tuples \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"conv1d_12\" with a weight list of length 64, but the layer was expecting 2 weights. Provided weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0..."
     ]
    }
   ],
   "source": [
    "npy_weights = np.load(path, allow_pickle=True)\n",
    "\n",
    "# Verify the number of weight sets\n",
    "print(f\"Number of weight sets in npy file: {len(npy_weights)}\")\n",
    "print(f\"Number of trainable weights in the model: {len(model.trainable_weights)}\")\n",
    "\n",
    "# Manually load weights for each layer\n",
    "for layer, layer_weights in zip(model.layers, npy_weights):\n",
    "    # Check if the layer has trainable weights\n",
    "    if layer.trainable_weights:\n",
    "        # Print shapes for debugging\n",
    "        print(f\"Layer {layer.name}: Expected {len(layer.trainable_weights)}, Found {len(layer_weights)}\")\n",
    "        for lw, tw in zip(layer_weights, layer.trainable_weights):\n",
    "            print(f\"  - Weight shape: expected {tw.shape}, found {lw.shape}\")\n",
    "        \n",
    "        # Set the weights\n",
    "        layer.set_weights(layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight set 0:\n",
      "  Shape: (1, 3, 64)\n",
      "Weight set 1:\n",
      "  Shape: (64,)\n",
      "Weight set 2:\n",
      "  Shape: (64,)\n",
      "Weight set 3:\n",
      "  Shape: (64,)\n",
      "Weight set 4:\n",
      "  Shape: (64,)\n",
      "Weight set 5:\n",
      "  Shape: (64,)\n",
      "Weight set 6:\n",
      "  Shape: (1, 64, 128)\n",
      "Weight set 7:\n",
      "  Shape: (128,)\n",
      "Weight set 8:\n",
      "  Shape: (128,)\n",
      "Weight set 9:\n",
      "  Shape: (128,)\n",
      "Weight set 10:\n",
      "  Shape: (128,)\n",
      "Weight set 11:\n",
      "  Shape: (128,)\n",
      "Weight set 12:\n",
      "  Shape: (1, 128, 1024)\n",
      "Weight set 13:\n",
      "  Shape: (1024,)\n",
      "Weight set 14:\n",
      "  Shape: (1024,)\n",
      "Weight set 15:\n",
      "  Shape: (1024,)\n",
      "Weight set 16:\n",
      "  Shape: (1024,)\n",
      "Weight set 17:\n",
      "  Shape: (1024,)\n",
      "Weight set 18:\n",
      "  Shape: (1024, 512)\n",
      "Weight set 19:\n",
      "  Shape: (512,)\n",
      "Weight set 20:\n",
      "  Shape: (512,)\n",
      "Weight set 21:\n",
      "  Shape: (512,)\n",
      "Weight set 22:\n",
      "  Shape: (512,)\n",
      "Weight set 23:\n",
      "  Shape: (512,)\n",
      "Weight set 24:\n",
      "  Shape: (512, 256)\n",
      "Weight set 25:\n",
      "  Shape: (256,)\n",
      "Weight set 26:\n",
      "  Shape: (256,)\n",
      "Weight set 27:\n",
      "  Shape: (256,)\n",
      "Weight set 28:\n",
      "  Shape: (256,)\n",
      "Weight set 29:\n",
      "  Shape: (256,)\n",
      "Weight set 30:\n",
      "  Shape: (256, 9)\n",
      "Weight set 31:\n",
      "  Shape: (9,)\n",
      "Weight set 32:\n",
      "  Shape: (1, 3, 64)\n",
      "Weight set 33:\n",
      "  Shape: (64,)\n",
      "Weight set 34:\n",
      "  Shape: (64,)\n",
      "Weight set 35:\n",
      "  Shape: (64,)\n",
      "Weight set 36:\n",
      "  Shape: (64,)\n",
      "Weight set 37:\n",
      "  Shape: (64,)\n",
      "Weight set 38:\n",
      "  Shape: (1, 64, 64)\n",
      "Weight set 39:\n",
      "  Shape: (64,)\n",
      "Weight set 40:\n",
      "  Shape: (64,)\n",
      "Weight set 41:\n",
      "  Shape: (64,)\n",
      "Weight set 42:\n",
      "  Shape: (64,)\n",
      "Weight set 43:\n",
      "  Shape: (64,)\n",
      "Weight set 44:\n",
      "  Shape: (1, 64, 64)\n",
      "Weight set 45:\n",
      "  Shape: (64,)\n",
      "Weight set 46:\n",
      "  Shape: (64,)\n",
      "Weight set 47:\n",
      "  Shape: (64,)\n",
      "Weight set 48:\n",
      "  Shape: (64,)\n",
      "Weight set 49:\n",
      "  Shape: (64,)\n",
      "Weight set 50:\n",
      "  Shape: (1, 64, 128)\n",
      "Weight set 51:\n",
      "  Shape: (128,)\n",
      "Weight set 52:\n",
      "  Shape: (128,)\n",
      "Weight set 53:\n",
      "  Shape: (128,)\n",
      "Weight set 54:\n",
      "  Shape: (128,)\n",
      "Weight set 55:\n",
      "  Shape: (128,)\n",
      "Weight set 56:\n",
      "  Shape: (1, 128, 1024)\n",
      "Weight set 57:\n",
      "  Shape: (1024,)\n",
      "Weight set 58:\n",
      "  Shape: (1024,)\n",
      "Weight set 59:\n",
      "  Shape: (1024,)\n",
      "Weight set 60:\n",
      "  Shape: (1024,)\n",
      "Weight set 61:\n",
      "  Shape: (1024,)\n",
      "Weight set 62:\n",
      "  Shape: (1024, 512)\n",
      "Weight set 63:\n",
      "  Shape: (512,)\n",
      "Weight set 64:\n",
      "  Shape: (512,)\n",
      "Weight set 65:\n",
      "  Shape: (512,)\n",
      "Weight set 66:\n",
      "  Shape: (512,)\n",
      "Weight set 67:\n",
      "  Shape: (512,)\n",
      "Weight set 68:\n",
      "  Shape: (512, 256)\n",
      "Weight set 69:\n",
      "  Shape: (256,)\n",
      "Weight set 70:\n",
      "  Shape: (256,)\n",
      "Weight set 71:\n",
      "  Shape: (256,)\n",
      "Weight set 72:\n",
      "  Shape: (256,)\n",
      "Weight set 73:\n",
      "  Shape: (256,)\n",
      "Weight set 74:\n",
      "  Shape: (256, 4096)\n",
      "Weight set 75:\n",
      "  Shape: (4096,)\n",
      "Weight set 76:\n",
      "  Shape: (1, 64, 64)\n",
      "Weight set 77:\n",
      "  Shape: (64,)\n",
      "Weight set 78:\n",
      "  Shape: (64,)\n",
      "Weight set 79:\n",
      "  Shape: (64,)\n",
      "Weight set 80:\n",
      "  Shape: (64,)\n",
      "Weight set 81:\n",
      "  Shape: (64,)\n",
      "Weight set 82:\n",
      "  Shape: (1, 64, 128)\n",
      "Weight set 83:\n",
      "  Shape: (128,)\n",
      "Weight set 84:\n",
      "  Shape: (128,)\n",
      "Weight set 85:\n",
      "  Shape: (128,)\n",
      "Weight set 86:\n",
      "  Shape: (128,)\n",
      "Weight set 87:\n",
      "  Shape: (128,)\n",
      "Weight set 88:\n",
      "  Shape: (1, 128, 1024)\n",
      "Weight set 89:\n",
      "  Shape: (1024,)\n",
      "Weight set 90:\n",
      "  Shape: (1024,)\n",
      "Weight set 91:\n",
      "  Shape: (1024,)\n",
      "Weight set 92:\n",
      "  Shape: (1024,)\n",
      "Weight set 93:\n",
      "  Shape: (1024,)\n",
      "Weight set 94:\n",
      "  Shape: (1024, 512)\n",
      "Weight set 95:\n",
      "  Shape: (512,)\n",
      "Weight set 96:\n",
      "  Shape: (512,)\n",
      "Weight set 97:\n",
      "  Shape: (512,)\n",
      "Weight set 98:\n",
      "  Shape: (512,)\n",
      "Weight set 99:\n",
      "  Shape: (512,)\n",
      "Weight set 100:\n",
      "  Shape: (512, 256)\n",
      "Weight set 101:\n",
      "  Shape: (256,)\n",
      "Weight set 102:\n",
      "  Shape: (256,)\n",
      "Weight set 103:\n",
      "  Shape: (256,)\n",
      "Weight set 104:\n",
      "  Shape: (256,)\n",
      "Weight set 105:\n",
      "  Shape: (256,)\n",
      "Weight set 106:\n",
      "  Shape: (256, 1)\n",
      "Weight set 107:\n",
      "  Shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "npy_weights = np.load(path, allow_pickle=True)\n",
    "\n",
    "# Inspect the weights for each set in the npy file\n",
    "for i, weight_set in enumerate(npy_weights):\n",
    "    print(f\"Weight set {i}:\")\n",
    "    if isinstance(weight_set, np.ndarray):\n",
    "        print(f\"  Shape: {weight_set.shape}\")\n",
    "    else:\n",
    "        print(\"  Multiple weights:\")\n",
    "        for w in weight_set:\n",
    "            print(f\"    Shape: {w.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers if needed (optional)\n",
    "# for layer in model.layers[:-N]:  # Replace N with the number of layers you want to train\n",
    "#     layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
